#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆAIæ–‡çŒ®æ•°æ®åˆ†æå·¥å…·
ä½¿ç”¨Gemini 2.5 Proæ¨¡å‹åˆ†æCNKIå¯¼å‡ºçš„æ–‡çŒ®æ•°æ®
ç”Ÿæˆæ›´ä¸°å¯Œçš„å¯è§†åŒ–HTMLæŠ¥å‘Š
"""

import argparse
import csv
import os
import sys
import json
from typing import List, Dict, Any
from openai import OpenAI

class EnhancedGeminiAnalyzer:
    """å¢å¼ºç‰ˆGeminiæ–‡çŒ®æ•°æ®åˆ†æå™¨"""
    
    def __init__(self, api_key: str = None, proxy_url: str = "https://yunwu.ai"):
        """
        åˆå§‹åŒ–å¢å¼ºç‰ˆGeminiåˆ†æå™¨
        
        Args:
            api_key: Gemini APIå¯†é’¥
            proxy_url: ä»£ç†æœåŠ¡å™¨åœ°å€
        """
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        self.proxy_url = proxy_url.rstrip('/')
        self.model_name = "gemini-2.5-pro"
        
        if not self.api_key:
            print("è­¦å‘Š: æœªæ‰¾åˆ°GEMINI_API_KEYç¯å¢ƒå˜é‡ï¼Œè¯·è®¾ç½®APIå¯†é’¥")
            print("å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¾ç½®:")
            print("export GEMINI_API_KEY='your_api_key_here'")
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼Œä½¿ç”¨ä»£ç†URL
        if self.api_key:
            self.client = OpenAI(
                api_key=self.api_key,
                base_url=f"{self.proxy_url}/v1"
            )
        else:
            self.client = None
    
    def load_csv_data(self, csv_file_path: str) -> List[Dict[str, Any]]:
        """
        ä»CSVæ–‡ä»¶åŠ è½½æ–‡çŒ®æ•°æ®
        
        Args:
            csv_file_path: CSVæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ–‡çŒ®æ•°æ®åˆ—è¡¨
        """
        if not os.path.exists(csv_file_path):
            raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
        
        papers = []
        try:
            with open(csv_file_path, 'r', encoding='utf-8-sig') as file:
                reader = csv.DictReader(file)
                for row in reader:
                    papers.append(dict(row))
            
            print(f"æˆåŠŸåŠ è½½ {len(papers)} æ¡æ–‡çŒ®æ•°æ®")
            return papers
            
        except Exception as e:
            raise Exception(f"è¯»å–CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def preprocess_data(self, papers: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        é¢„å¤„ç†æ–‡çŒ®æ•°æ®ï¼Œç”Ÿæˆè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            papers: æ–‡çŒ®æ•°æ®åˆ—è¡¨
            
        Returns:
            é¢„å¤„ç†åçš„ç»Ÿè®¡æ•°æ®
        """
        stats = {
            'total_papers': len(papers),
            'years': [],
            'year_counts': {},
            'source_counts': {},
            'keyword_counts': {},
            'author_counts': {},
            'citation_stats': {'total': 0, 'max': 0, 'avg': 0, 'distribution': {}},
            'download_stats': {'total': 0, 'max': 0, 'avg': 0, 'distribution': {}},
            'papers_data': []
        }
        
        all_keywords = []
        all_authors = []
        citations = []
        downloads = []
        
        # å¤„ç†æ¯ç¯‡æ–‡çŒ®
        for i, paper in enumerate(papers, 1):
            # æå–å¹´ä»½
            date_str = paper.get('å‘è¡¨æ—¶é—´', '')
            year = None
            if date_str and len(date_str) >= 4:
                try:
                    year = int(date_str[:4])
                    if 1900 <= year <= 2030:  # åˆç†çš„å¹´ä»½èŒƒå›´
                        stats['years'].append(year)
                        stats['year_counts'][year] = stats['year_counts'].get(year, 0) + 1
                except:
                    pass
            
            # å¤„ç†æœŸåˆŠ
            source = paper.get('æ¥æº', '').strip()
            if source:
                stats['source_counts'][source] = stats['source_counts'].get(source, 0) + 1
            
            # å¤„ç†å…³é”®è¯
            keywords_str = paper.get('å…³é”®è¯', '')
            paper_keywords = []
            if keywords_str:
                keywords = [k.strip() for k in keywords_str.replace('ï¼›', ';').replace(',', ';').split(';') if k.strip()]
                paper_keywords = keywords
                all_keywords.extend(keywords)
            
            # å¤„ç†ä½œè€…
            authors_str = paper.get('ä½œè€…', '')
            paper_authors = []
            if authors_str:
                authors = [a.strip() for a in authors_str.replace('ï¼›', ';').replace(',', ';').split(';') if a.strip()]
                paper_authors = authors
                all_authors.extend(authors)
            
            # å¤„ç†è¢«å¼•å’Œä¸‹è½½æ¬¡æ•°
            try:
                citation_count = int(paper.get('è¢«å¼•', '0') or '0')
                citations.append(citation_count)
            except:
                citations.append(0)
            
            try:
                download_count = int(paper.get('ä¸‹è½½', '0') or '0')
                downloads.append(download_count)
            except:
                downloads.append(0)
            
            # æ„å»ºæ–‡çŒ®æ•°æ®
            paper_data = {
                'id': i,
                'title': paper.get('é¢˜å', 'N/A').strip(),
                'authors': paper.get('ä½œè€…', 'N/A').strip(),
                'source': source or 'N/A',
                'date': paper.get('å‘è¡¨æ—¶é—´', 'N/A').strip(),
                'year': year,
                'citations': citations[-1],
                'downloads': downloads[-1],
                'keywords': ', '.join(paper_keywords) if paper_keywords else 'N/A',
                'abstract': (paper.get('æ‘˜è¦', '') or '').strip()[:300] + '...' if paper.get('æ‘˜è¦', '') else 'N/A',
                'database': paper.get('æ•°æ®åº“', 'N/A').strip(),
                'funding': paper.get('åŸºé‡‘èµ„åŠ©', 'N/A').strip(),
                'doi': paper.get('DOI', 'N/A').strip()
            }
            stats['papers_data'].append(paper_data)
        
        # ç»Ÿè®¡å…³é”®è¯å’Œä½œè€…
        for keyword in all_keywords:
            stats['keyword_counts'][keyword] = stats['keyword_counts'].get(keyword, 0) + 1
        
        for author in all_authors:
            stats['author_counts'][author] = stats['author_counts'].get(author, 0) + 1
        
        # è®¡ç®—è¢«å¼•å’Œä¸‹è½½ç»Ÿè®¡
        if citations:
            stats['citation_stats']['total'] = sum(citations)
            stats['citation_stats']['max'] = max(citations)
            stats['citation_stats']['avg'] = round(sum(citations) / len(citations), 2)
            
            # è¢«å¼•åˆ†å¸ƒ
            citation_ranges = {'0': 0, '1-5': 0, '6-10': 0, '11-20': 0, '21-50': 0, '50+': 0}
            for c in citations:
                if c == 0:
                    citation_ranges['0'] += 1
                elif 1 <= c <= 5:
                    citation_ranges['1-5'] += 1
                elif 6 <= c <= 10:
                    citation_ranges['6-10'] += 1
                elif 11 <= c <= 20:
                    citation_ranges['11-20'] += 1
                elif 21 <= c <= 50:
                    citation_ranges['21-50'] += 1
                else:
                    citation_ranges['50+'] += 1
            stats['citation_stats']['distribution'] = citation_ranges
        
        if downloads:
            stats['download_stats']['total'] = sum(downloads)
            stats['download_stats']['max'] = max(downloads)
            stats['download_stats']['avg'] = round(sum(downloads) / len(downloads), 2)
        
        return stats
    
    def generate_enhanced_prompt(self, stats: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆå¢å¼ºç‰ˆåˆ†ææç¤ºè¯
        
        Args:
            stats: é¢„å¤„ç†çš„ç»Ÿè®¡æ•°æ®
            
        Returns:
            å¢å¼ºç‰ˆåˆ†ææç¤ºè¯
        """
        # è·å–TOPæ•°æ®
        top_sources = dict(list(sorted(stats['source_counts'].items(), key=lambda x: x[1], reverse=True)[:10]))
        top_keywords = dict(list(sorted(stats['keyword_counts'].items(), key=lambda x: x[1], reverse=True)[:20]))
        top_authors = dict(list(sorted(stats['author_counts'].items(), key=lambda x: x[1], reverse=True)[:10]))
        
        year_range = f"{min(stats['years'])}-{max(stats['years'])}" if stats['years'] else "æœªçŸ¥"
        
        # å°†papers_dataè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²ï¼Œé¿å…f-stringä¸­çš„å¤æ‚è¡¨è¾¾å¼
        papers_json_str = json.dumps(stats['papers_data'][:3], ensure_ascii=False, indent=2)
        year_counts_str = json.dumps(dict(sorted(stats['year_counts'].items())), ensure_ascii=False)
        top_sources_str = json.dumps(top_sources, ensure_ascii=False)
        top_keywords_str = json.dumps(top_keywords, ensure_ascii=False)
        top_authors_str = json.dumps(top_authors, ensure_ascii=False)
        citation_dist_str = json.dumps(stats['citation_stats']['distribution'], ensure_ascii=False)
        
        prompt = f"""
ä½œä¸ºé¡¶çº§å­¦æœ¯æ–‡çŒ®æ•°æ®åˆ†æä¸“å®¶å’Œå‰ç«¯å¯è§†åŒ–å·¥ç¨‹å¸ˆï¼Œè¯·ä¸ºä»¥ä¸‹CNKIæ–‡çŒ®æ•°æ®ç”Ÿæˆä¸€ä¸ªä¸“ä¸šçº§çš„ã€å®Œæ•´çš„HTMLå¯è§†åŒ–åˆ†ææŠ¥å‘Šã€‚

=== æ•°æ®ç»Ÿè®¡æ€»è§ˆ ===
ğŸ“Š æ€»æ–‡çŒ®æ•°é‡: {stats['total_papers']}ç¯‡
ğŸ“… å‘è¡¨å¹´ä»½èŒƒå›´: {year_range}
ğŸ“° è¦†ç›–æœŸåˆŠæ•°é‡: {len(stats['source_counts'])}ç§
ğŸ”‘ å…³é”®è¯æ€»æ•°: {len(stats['keyword_counts'])}ä¸ª
ğŸ‘¥ æ¶‰åŠä½œè€…æ•°: {len(stats['author_counts'])}äºº
ğŸ“ˆ æ€»è¢«å¼•æ¬¡æ•°: {stats['citation_stats']['total']}
â­ å¹³å‡è¢«å¼•æ¬¡æ•°: {stats['citation_stats']['avg']}
ğŸ“¥ æ€»ä¸‹è½½æ¬¡æ•°: {stats['download_stats']['total']}

=== è¯¦ç»†ç»Ÿè®¡æ•°æ® ===

**å¹´åº¦å‘æ–‡ç»Ÿè®¡:**
{year_counts_str}

**æœŸåˆŠåˆ†å¸ƒTOP10:**
{top_sources_str}

**é«˜é¢‘å…³é”®è¯TOP20:**
{top_keywords_str}

**é«˜äº§ä½œè€…TOP10:**
{top_authors_str}

**è¢«å¼•åˆ†å¸ƒåŒºé—´:**
{citation_dist_str}

=== HTMLæŠ¥å‘Šç”Ÿæˆè¦æ±‚ ===

è¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„ã€ç°ä»£åŒ–çš„ã€å¯ç‹¬ç«‹è¿è¡Œçš„HTMLå­¦æœ¯åˆ†ææŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹æ¨¡å—ï¼š

## 1. é¡µé¢æ¶æ„ä¸è®¾è®¡
- **æ¡†æ¶**: Bootstrap 5.3.0 + è‡ªå®šä¹‰CSS + JavaScript
- **ä¸»é¢˜**: æ·±è‰²/æµ…è‰²ä¸»é¢˜åˆ‡æ¢ (é»˜è®¤æ·±è‰²ä¸»é¢˜)
- **å¸ƒå±€**: å“åº”å¼è®¾è®¡ï¼Œæ”¯æŒæ¡Œé¢ç«¯å’Œç§»åŠ¨ç«¯
- **å¯¼èˆª**: å›ºå®šé¡¶éƒ¨å¯¼èˆªæ ï¼ŒåŒ…å«5ä¸ªä¸»è¦æ¨¡å—
  - ğŸ“Š æ•°æ®æ¦‚è§ˆ (Overview)
  - ğŸ“ˆ å›¾è¡¨åˆ†æ (Charts) 
  - ğŸ“š æ–‡çŒ®åº“ (Literature)
  - ğŸ“‹ ç»Ÿè®¡æŠ¥å‘Š (Statistics)
  - ğŸ’¡ ç ”ç©¶å»ºè®® (Insights)
- **é…è‰²**: ç°ä»£åŒ–é…è‰²æ–¹æ¡ˆ (ä¸»è‰²è°ƒ: #3B82F6, è¾…è‰²: #10B981, èƒŒæ™¯æ¸å˜)
- **æ•ˆæœ**: æ¯›ç»ç’ƒæ•ˆæœã€å¹³æ»‘è¿‡æ¸¡åŠ¨ç”»ã€åŠ è½½åŠ¨ç”»

## 2. æ ¸å¿ƒå¯è§†åŒ–æ¨¡å— (ä½¿ç”¨Chart.js 4.4.0)

### A) å‘è¡¨è¶‹åŠ¿åˆ†æå›¾
- **ç±»å‹**: æ··åˆå›¾è¡¨ (æŸ±çŠ¶å›¾ + æŠ˜çº¿å›¾)
- **æ•°æ®**: å¹´åº¦å‘æ–‡é‡ + ç´¯è®¡è¶‹åŠ¿
- **äº¤äº’**: æ‚¬æµ®æ˜¾ç¤ºè¯¦ç»†æ•°æ®

### B) æœŸåˆŠå½±å“åŠ›åˆ†æ
- **ç±»å‹**: æ°´å¹³æŸ±çŠ¶å›¾
- **æ•°æ®**: TOP10æœŸåˆŠå‘æ–‡é‡
- **åŠŸèƒ½**: ç‚¹å‡»æŸ¥çœ‹è¯¥æœŸåˆŠçš„æ‰€æœ‰æ–‡çŒ®

### C) å…³é”®è¯äº‘å›¾
- **åº“**: wordcloud2.js
- **æ•°æ®**: å…³é”®è¯é¢‘æ¬¡
- **äº¤äº’**: ç‚¹å‡»å…³é”®è¯ç­›é€‰ç›¸å…³æ–‡çŒ®

### D) è¢«å¼•åˆ†æå›¾è¡¨
- **ç±»å‹**: åˆ†ç»„æŸ±çŠ¶å›¾ + æ•£ç‚¹å›¾
- **å†…å®¹**: è¢«å¼•åˆ†å¸ƒåŒºé—´ + é«˜è¢«å¼•æ–‡çŒ®æ ‡æ³¨
- **åŠŸèƒ½**: è¯†åˆ«é«˜å½±å“åŠ›æ–‡çŒ®

### E) ä½œè€…åˆä½œç½‘ç»œ
- **ç±»å‹**: ç½‘ç»œå…³ç³»å›¾ (ç®€åŒ–ç‰ˆ)
- **æ•°æ®**: é«˜äº§ä½œè€…åŠå…¶åˆä½œå…³ç³»
- **äº¤äº’**: èŠ‚ç‚¹ç‚¹å‡»æŸ¥çœ‹ä½œè€…è¯¦æƒ…

### F) ç ”ç©¶çƒ­ç‚¹æ—¶é—´è½´
- **ç±»å‹**: æ—¶é—´è½´ + çƒ­åŠ›å›¾
- **å†…å®¹**: å…³é”®è¯éšæ—¶é—´çš„å˜åŒ–è¶‹åŠ¿

## 3. å®Œæ•´æ–‡çŒ®æ•°æ®è¡¨ (DataTables 1.13.6)

**åŒ…å«æ‰€æœ‰ {stats['total_papers']} ç¯‡æ–‡çŒ®çš„å®Œæ•´ä¿¡æ¯:**

**ç¤ºä¾‹æ•°æ®ç»“æ„:**
{papers_json_str}

**è¡¨æ ¼åŠŸèƒ½:**
- âœ… å…¨æ–‡æœç´¢ (æ”¯æŒä¸­æ–‡)
- âœ… å¤šåˆ—æ’åº
- âœ… åˆ†é¡µæ˜¾ç¤º (æ¯é¡µ20æ¡)
- âœ… åˆ—ç­›é€‰å™¨
- âœ… å¯¼å‡ºåŠŸèƒ½ (CSV/Excel/PDF)
- âœ… ç‚¹å‡»æ ‡é¢˜å±•å¼€æ‘˜è¦
- âœ… å“åº”å¼è¡¨æ ¼è®¾è®¡

**è¡¨æ ¼åˆ—è®¾è®¡:**
1. åºå· | 2. é¢˜å | 3. ä½œè€… | 4. æœŸåˆŠ | 5. å‘è¡¨æ—¶é—´
6. è¢«å¼•æ¬¡æ•° | 7. ä¸‹è½½æ¬¡æ•° | 8. å…³é”®è¯ | 9. æ“ä½œ

## 4. æ•°æ®ä»ªè¡¨ç›˜
**å…³é”®æŒ‡æ ‡å¡ç‰‡:**
- ğŸ“Š æ€»æ–‡çŒ®æ•°: {stats['total_papers']}
- ğŸ“… æ—¶é—´è·¨åº¦: {year_range}
- ğŸ“ˆ æ€»è¢«å¼•æ•°: {stats['citation_stats']['total']}
- â­ å¹³å‡è¢«å¼•: {stats['citation_stats']['avg']}
- ğŸ“° æœŸåˆŠè¦†ç›–: {len(stats['source_counts'])}ç§
- ğŸ”‘ å…³é”®è¯æ•°: {len(stats['keyword_counts'])}ä¸ª

**åŠ¨æ€ç»Ÿè®¡å›¾è¡¨:**
- ç ”ç©¶æ´»è·ƒåº¦æŒ‡æ•°
- å­¦æœ¯å½±å“åŠ›è¯„åˆ†
- å›½é™…åŒ–ç¨‹åº¦åˆ†æ

## 5. æ·±åº¦åˆ†ææŠ¥å‘Š

### A) ç ”ç©¶è¶‹åŠ¿æ¼”å˜
- å‘æ–‡é‡å¹´åº¦å˜åŒ–è¶‹åŠ¿åˆ†æ
- ç ”ç©¶çƒ­ç‚¹çš„å…´èµ·å’Œè¡°è½
- å­¦ç§‘å‘å±•é˜¶æ®µåˆ¤æ–­

### B) æœŸåˆŠè´¨é‡è¯„ä¼°
- æ ¸å¿ƒæœŸåˆŠå‘æ–‡åˆ†å¸ƒ
- æœŸåˆŠå½±å“å› å­å¯¹æ¯”
- æœŸåˆŠä¸“ä¸šåŒ–ç¨‹åº¦åˆ†æ

### C) å­¦æœ¯å½±å“åŠ›åˆ†æ
- é«˜è¢«å¼•æ–‡çŒ®ç‰¹å¾åˆ†æ
- å­¦æœ¯è´¡çŒ®åº¦è¯„ä¼°
- å¼•ç”¨ç½‘ç»œåˆ†æ

### D) ç ”ç©¶åˆä½œæ¨¡å¼
- ä½œè€…åˆä½œç½‘ç»œåˆ†æ
- æœºæ„åˆä½œç¨‹åº¦
- è·¨å­¦ç§‘ç ”ç©¶è¯†åˆ«

### E) åˆ›æ–°ç‚¹è¯†åˆ«
- æ–°å…´å…³é”®è¯å‘ç°
- ç ”ç©¶ç©ºç™½é¢†åŸŸè¯†åˆ«
- æ–¹æ³•è®ºåˆ›æ–°è¶‹åŠ¿

## 6. æ™ºèƒ½ç ”ç©¶å»ºè®®

### A) æœªæ¥ç ”ç©¶æ–¹å‘
- åŸºäºè¶‹åŠ¿çš„çƒ­ç‚¹é¢„æµ‹
- ç ”ç©¶ç©ºç™½é¢†åŸŸæ¨è
- è·¨å­¦ç§‘èåˆæœºä¼š

### B) åˆä½œæœºä¼šåˆ†æ
- æ½œåœ¨åˆä½œä¼™ä¼´æ¨è
- ä¼˜åŠ¿æœŸåˆŠæŠ•ç¨¿å»ºè®®
- ç ”ç©¶å›¢é˜Ÿç»„å»ºå»ºè®®

### C) æ–¹æ³•è®ºæ”¹è¿›
- ç ”ç©¶æ–¹æ³•åˆ›æ–°å»ºè®®
- æ•°æ®æ”¶é›†ä¼˜åŒ–æ–¹æ¡ˆ
- åˆ†ææ¡†æ¶æ”¹è¿›æ€è·¯

## æŠ€æœ¯å®ç°è¦æ±‚:

### HTMLç»“æ„:
```html
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <!-- Metaæ ‡ç­¾ã€æ ‡é¢˜ã€CDNé“¾æ¥ -->
</head>
<body>
    <!-- å¯¼èˆªæ  -->
    <!-- ä¸»è¦å†…å®¹åŒºåŸŸ -->
    <!-- æ‰€æœ‰JavaScriptä»£ç  -->
</body>
</html>
```

### å¿…éœ€çš„CDNé“¾æ¥:
- Bootstrap 5.3.0 (CSS + JS)
- Chart.js 4.4.0
- DataTables 1.13.6 (å«ä¸­æ–‡è¯­è¨€åŒ…)
- wordcloud2.js
- Font Awesome 6.4.0 (å›¾æ ‡)

### æ ¸å¿ƒè¦æ±‚:
1. âœ… å®Œæ•´HTMLæ–‡æ¡£ï¼Œå¯ç›´æ¥åœ¨æµè§ˆå™¨æ‰“å¼€
2. âœ… æ‰€æœ‰{stats['total_papers']}ç¯‡æ–‡çŒ®æ•°æ®å®Œæ•´å±•ç¤º
3. âœ… å›¾è¡¨æ•°æ®å‡†ç¡®å¯¹åº”ç»Ÿè®¡ç»“æœ
4. âœ… ç§»åŠ¨ç«¯å®Œç¾é€‚é…
5. âœ… ä¸­æ–‡å­—ç¬¦æ­£ç¡®æ˜¾ç¤º
6. âœ… åŠ è½½æ€§èƒ½ä¼˜åŒ–
7. âœ… ä»£ç ç»“æ„æ¸…æ™°ï¼Œä¾¿äºç»´æŠ¤

### äº¤äº’ä½“éªŒ:
- ğŸ¯ å¹³æ»‘çš„é¡µé¢æ»šåŠ¨å’Œè·³è½¬
- ğŸ¨ ä¼˜é›…çš„åŠ è½½åŠ¨ç”»
- ğŸ”„ ä¸»é¢˜åˆ‡æ¢åŠŸèƒ½
- ğŸ“± ç§»åŠ¨ç«¯æ‰‹åŠ¿æ”¯æŒ
- ğŸ” æ™ºèƒ½æœç´¢å»ºè®®
- ğŸ’¾ æ•°æ®å¯¼å‡ºåŠŸèƒ½

è¯·ç”Ÿæˆå®Œæ•´çš„HTMLä»£ç ï¼Œç¡®ä¿ä¸“ä¸šæ€§ã€ç¾è§‚æ€§å’ŒåŠŸèƒ½å®Œæ•´æ€§ï¼
"""
        return prompt
    
    def call_gemini_api(self, prompt: str) -> str:
        """
        è°ƒç”¨Gemini APIè¿›è¡Œåˆ†æ
        
        Args:
            prompt: åˆ†ææç¤ºè¯
            
        Returns:
            åˆ†æç»“æœ
        """
        if not self.api_key:
            raise Exception("æœªè®¾ç½®GEMINI_API_KEYï¼Œæ— æ³•è°ƒç”¨API")
        
        try:
            print("ğŸš€ æ­£åœ¨è°ƒç”¨Gemini 2.5 Proè¿›è¡Œæ·±åº¦åˆ†æ...")
            print("ğŸ’¡ æç¤ºï¼šç”Ÿæˆå®Œæ•´HTMLå¯è§†åŒ–æŠ¥å‘Šå¯èƒ½éœ€è¦2-3åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
            
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½ä¸–ç•Œé¡¶çº§çš„å­¦æœ¯æ–‡çŒ®æ•°æ®åˆ†æä¸“å®¶å’Œå…¨æ ˆå¼€å‘å·¥ç¨‹å¸ˆï¼Œæ“…é•¿ä½¿ç”¨ç°ä»£å‰ç«¯æŠ€æœ¯ç”Ÿæˆä¸“ä¸šçº§çš„å­¦æœ¯å¯è§†åŒ–æŠ¥å‘Šã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ›å»ºå®Œæ•´çš„ã€å¯ç‹¬ç«‹è¿è¡Œçš„HTMLæ–‡æ¡£ï¼ŒåŒ…å«ä¸°å¯Œçš„äº¤äº’åŠŸèƒ½ã€ç¾è§‚çš„å¯è§†åŒ–å›¾è¡¨å’Œæ·±åº¦çš„å­¦æœ¯åˆ†æå†…å®¹ã€‚è¯·ç¡®ä¿ç”Ÿæˆçš„HTMLä»£ç å®Œæ•´ã€é«˜è´¨é‡ã€ç¬¦åˆç°ä»£Webæ ‡å‡†ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=8000,  # å¢åŠ tokené™åˆ¶ä»¥ç”Ÿæˆæ›´å®Œæ•´çš„HTML
                temperature=0.2   # é™ä½éšæœºæ€§ï¼Œæé«˜ç”Ÿæˆè´¨é‡å’Œä¸€è‡´æ€§
            )
            
            return response.choices[0].message.content
                
        except Exception as e:
            raise Exception(f"APIè°ƒç”¨å¤±è´¥: {e}")
    
    def save_analysis_report(self, analysis_result: str, output_file: str = None) -> str:
        """
        ä¿å­˜åˆ†ææŠ¥å‘Š
        
        Args:
            analysis_result: åˆ†æç»“æœ
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if not output_file:
            timestamp = __import__('datetime').datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"enhanced_analysis_report_{timestamp}.html"
        
        try:
            # å¦‚æœè¿”å›çš„æ˜¯HTMLä»£ç ï¼Œç›´æ¥ä¿å­˜
            if analysis_result.strip().startswith('<!DOCTYPE html') or analysis_result.strip().startswith('<html'):
                with open(output_file, 'w', encoding='utf-8') as file:
                    file.write(analysis_result)
            else:
                # å¦‚æœä¸æ˜¯HTMLï¼ŒåŒ…è£…ä¸ºHTMLæ ¼å¼
                html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>å¢å¼ºç‰ˆæ–‡çŒ®æ•°æ®AIåˆ†ææŠ¥å‘Š</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {{
            font-family: 'Microsoft YaHei', 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            margin: 0;
            padding: 20px;
        }}
        .container {{
            background: rgba(255, 255, 255, 0.95);
            padding: 40px;
            border-radius: 15px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            backdrop-filter: blur(10px);
            max-width: 1200px;
            margin: 0 auto;
        }}
        h1 {{
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 15px;
            margin-bottom: 30px;
        }}
        h2 {{
            color: #34495e;
            margin-top: 40px;
            margin-bottom: 20px;
        }}
        .meta-info {{
            background: linear-gradient(45deg, #f39c12, #f1c40f);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 30px;
        }}
        .content {{
            background: #f8f9fa;
            padding: 25px;
            border-radius: 10px;
            border-left: 5px solid #3498db;
        }}
        pre {{
            background: #2c3e50;
            color: #ecf0f1;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 14px;
        }}
        .highlight {{
            background: #3498db;
            color: white;
            padding: 2px 6px;
            border-radius: 4px;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸš€ å¢å¼ºç‰ˆæ–‡çŒ®æ•°æ®AIåˆ†ææŠ¥å‘Š</h1>
        <div class="meta-info">
            <h3>ğŸ“‹ æŠ¥å‘Šä¿¡æ¯</h3>
            <p><strong>ğŸ•’ ç”Ÿæˆæ—¶é—´:</strong> {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p><strong>ğŸ¤– åˆ†ææ¨¡å‹:</strong> <span class="highlight">{self.model_name}</span></p>
            <p><strong>âš¡ ç‰ˆæœ¬:</strong> Enhanced AI Analyzer v2.0</p>
        </div>
        <div class="content">
            <h2>ğŸ“„ åˆ†æå†…å®¹</h2>
            <pre>{analysis_result}</pre>
        </div>
        <div class="mt-4 text-center">
            <p class="text-muted">ğŸ’¡ æç¤ºï¼šå¦‚æœå†…å®¹ä¸æ˜¯HTMLæ ¼å¼ï¼Œè¯·æ£€æŸ¥APIå“åº”æˆ–é‡æ–°ç”Ÿæˆ</p>
        </div>
    </div>
</body>
</html>"""
                with open(output_file, 'w', encoding='utf-8') as file:
                    file.write(html_content)
            
            print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
            return output_file
            
        except Exception as e:
            raise Exception(f"ä¿å­˜åˆ†ææŠ¥å‘Šæ—¶å‡ºé”™: {e}")
    
    def analyze(self, csv_file_path: str, output_file: str = None) -> str:
        """
        æ‰§è¡Œå®Œæ•´çš„å¢å¼ºç‰ˆæ–‡çŒ®æ•°æ®åˆ†ææµç¨‹
        
        Args:
            csv_file_path: CSVæ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            åˆ†ææŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        try:
            print("ğŸ”„ å¼€å§‹å¢å¼ºç‰ˆæ–‡çŒ®æ•°æ®åˆ†æ...")
            
            # 1. åŠ è½½æ•°æ®
            print("ğŸ“‚ æ­£åœ¨åŠ è½½æ–‡çŒ®æ•°æ®...")
            papers = self.load_csv_data(csv_file_path)
            
            if not papers:
                raise Exception("CSVæ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
            
            # 2. æ•°æ®é¢„å¤„ç†
            print("âš™ï¸ æ­£åœ¨è¿›è¡Œæ•°æ®é¢„å¤„ç†å’Œç»Ÿè®¡åˆ†æ...")
            stats = self.preprocess_data(papers)
            
            # 3. ç”Ÿæˆå¢å¼ºç‰ˆæç¤ºè¯
            print("ğŸ¯ æ­£åœ¨å‡†å¤‡å¢å¼ºç‰ˆåˆ†ææç¤ºè¯...")
            prompt = self.generate_enhanced_prompt(stats)
            
            # 4. è°ƒç”¨AIåˆ†æ
            analysis_result = self.call_gemini_api(prompt)
            
            # 5. ä¿å­˜åˆ†ææŠ¥å‘Š
            report_file = self.save_analysis_report(analysis_result, output_file)
            
            print("\n" + "="*60)
            print("ğŸ‰ å¢å¼ºç‰ˆåˆ†æå®Œæˆï¼")
            print("="*60)
            print(f"ğŸ“Š åˆ†æäº† {len(papers)} æ¡æ–‡çŒ®")
            print(f"ğŸ“… å¹´ä»½èŒƒå›´: {min(stats['years']) if stats['years'] else 'æœªçŸ¥'} - {max(stats['years']) if stats['years'] else 'æœªçŸ¥'}")
            print(f"ğŸ“° æ¶‰åŠæœŸåˆŠ: {len(stats['source_counts'])} ç§")
            print(f"ğŸ”‘ å…³é”®è¯æ•°: {len(stats['keyword_counts'])} ä¸ª")
            print(f"ğŸ‘¥ ä½œè€…äººæ•°: {len(stats['author_counts'])} äºº")
            print(f"ğŸ“ˆ æ€»è¢«å¼•æ•°: {stats['citation_stats']['total']}")
            print(f"ğŸ“„ æŠ¥å‘Šæ–‡ä»¶: {report_file}")
            print("="*60)
            
            return report_file
            
        except Exception as e:
            print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            sys.exit(1)

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='ğŸš€ å¢å¼ºç‰ˆAIæ–‡çŒ®æ•°æ®åˆ†æå·¥å…· - ä½¿ç”¨Gemini 2.5 Proç”Ÿæˆä¸“ä¸šå¯è§†åŒ–æŠ¥å‘Š',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ğŸ“– ä½¿ç”¨ç¤ºä¾‹:
  python ai_analyze_enhanced.py -i cnki_papers_20250623_214224.csv
  python ai_analyze_enhanced.py -i data.csv -o my_enhanced_report.html
  python ai_analyze_enhanced.py -i data.csv --api-key your_key_here

ğŸŒ ç¯å¢ƒå˜é‡:
  GEMINI_API_KEY    Gemini APIå¯†é’¥

âœ¨ åŠŸèƒ½ç‰¹ç‚¹:
  â€¢ ğŸ¨ ç°ä»£åŒ–å¯è§†åŒ–ç•Œé¢
  â€¢ ğŸ“Š ä¸°å¯Œçš„äº¤äº’å¼å›¾è¡¨
  â€¢ ğŸ“š å®Œæ•´çš„æ–‡çŒ®æ•°æ®è¡¨æ ¼
  â€¢ ğŸ” æ™ºèƒ½æœç´¢å’Œç­›é€‰
  â€¢ ğŸ“± ç§»åŠ¨ç«¯å®Œç¾é€‚é…
  â€¢ ğŸŒ“ æ·±è‰²/æµ…è‰²ä¸»é¢˜åˆ‡æ¢
        """
    )
    
    parser.add_argument(
        '-i', '--input',
        required=True,
        help='ğŸ“‚ è¾“å…¥çš„CSVæ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '-o', '--output',
        help='ğŸ“„ è¾“å‡ºåˆ†ææŠ¥å‘Šçš„æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰'
    )
    
    parser.add_argument(
        '--api-key',
        help='ğŸ”‘ Gemini APIå¯†é’¥ï¼ˆå¯é€‰ï¼Œä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡GEMINI_API_KEYè®¾ç½®ï¼‰'
    )
    
    parser.add_argument(
        '--proxy-url',
        default='https://yunwu.ai',
        help='ğŸŒ ä»£ç†æœåŠ¡å™¨åœ°å€ï¼ˆé»˜è®¤: https://yunwu.aiï¼‰'
    )
    
    return parser.parse_args()

def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    print("ğŸš€ å¢å¼ºç‰ˆAIæ–‡çŒ®æ•°æ®åˆ†æå·¥å…·")
    print("="*50)
    print(f"ğŸ“‚ è¾“å…¥æ–‡ä»¶: {args.input}")
    print(f"ğŸŒ ä»£ç†åœ°å€: {args.proxy_url}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: gemini-2.5-pro")
    print(f"âš¡ ç‰ˆæœ¬: Enhanced v2.0")
    print("="*50)
    print()
    
    # åˆ›å»ºå¢å¼ºç‰ˆåˆ†æå™¨
    analyzer = EnhancedGeminiAnalyzer(
        api_key=args.api_key,
        proxy_url=args.proxy_url
    )
    
    # æ‰§è¡Œåˆ†æ
    try:
        report_file = analyzer.analyze(args.input, args.output)
        print(f"\nğŸŠ åˆ†æå®Œæˆï¼å¢å¼ºç‰ˆæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        print("ğŸ’¡ æç¤ºï¼šç”¨æµè§ˆå™¨æ‰“å¼€HTMLæ–‡ä»¶æŸ¥çœ‹å®Œæ•´çš„å¯è§†åŒ–æŠ¥å‘Š")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†åˆ†æè¿‡ç¨‹")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
